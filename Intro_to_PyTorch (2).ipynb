{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "name": "Intro_to_PyTorch.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "toc_visible": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.6.7"
    },
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "4d7dab5d56d34b598b514c6a3a98b5e5": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "state": {
            "_view_name": "HBoxView",
            "_dom_classes": [],
            "_model_name": "HBoxModel",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "box_style": "",
            "layout": "IPY_MODEL_6097a8fbb58f4013b41194a5ae544656",
            "_model_module": "@jupyter-widgets/controls",
            "children": [
              "IPY_MODEL_ed624df9e1cf49ea8c864581851a45d7",
              "IPY_MODEL_89a798fcb3fb4364b96c1de26bbaff34"
            ]
          }
        },
        "6097a8fbb58f4013b41194a5ae544656": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "ed624df9e1cf49ea8c864581851a45d7": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "IntProgressModel",
          "state": {
            "_view_name": "ProgressView",
            "style": "IPY_MODEL_d82d1936f55344238f00f226f86caae1",
            "_dom_classes": [],
            "description": "",
            "_model_name": "IntProgressModel",
            "bar_style": "success",
            "max": 1,
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": 1,
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "orientation": "horizontal",
            "min": 0,
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_bc3f0f777f034019982bfbb1a1b61330"
          }
        },
        "89a798fcb3fb4364b96c1de26bbaff34": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "state": {
            "_view_name": "HTMLView",
            "style": "IPY_MODEL_be61d9e8318d4ec9b42bc1ae8ba7a591",
            "_dom_classes": [],
            "description": "",
            "_model_name": "HTMLModel",
            "placeholder": "​",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": "9920512it [00:01, 8826154.48it/s]",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_17e0eea786cb425c91c9d16189ee6753"
          }
        },
        "d82d1936f55344238f00f226f86caae1": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "ProgressStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "bar_color": null,
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "bc3f0f777f034019982bfbb1a1b61330": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "be61d9e8318d4ec9b42bc1ae8ba7a591": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "DescriptionStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "17e0eea786cb425c91c9d16189ee6753": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "26e8e4195a054c4e8245560027224ef1": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "state": {
            "_view_name": "HBoxView",
            "_dom_classes": [],
            "_model_name": "HBoxModel",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "box_style": "",
            "layout": "IPY_MODEL_ea0f7ffaa0a8406ba88674b69c4083c1",
            "_model_module": "@jupyter-widgets/controls",
            "children": [
              "IPY_MODEL_1e7e8c393853471abfcf93336e11995f",
              "IPY_MODEL_247075d916c643de8452764a93572a56"
            ]
          }
        },
        "ea0f7ffaa0a8406ba88674b69c4083c1": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "1e7e8c393853471abfcf93336e11995f": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "IntProgressModel",
          "state": {
            "_view_name": "ProgressView",
            "style": "IPY_MODEL_de6898f868244050bdecb70aa8a0daa1",
            "_dom_classes": [],
            "description": "",
            "_model_name": "IntProgressModel",
            "bar_style": "success",
            "max": 1,
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": 1,
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "orientation": "horizontal",
            "min": 0,
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_7f49c2ed443a4c0f80bc8ea216b50269"
          }
        },
        "247075d916c643de8452764a93572a56": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "state": {
            "_view_name": "HTMLView",
            "style": "IPY_MODEL_42e54e1ecb0943e7b551e91a576623c6",
            "_dom_classes": [],
            "description": "",
            "_model_name": "HTMLModel",
            "placeholder": "​",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": "32768it [00:00, 93375.83it/s]",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_dfb48ab2a8d246fea96de480973e4efe"
          }
        },
        "de6898f868244050bdecb70aa8a0daa1": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "ProgressStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "bar_color": null,
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "7f49c2ed443a4c0f80bc8ea216b50269": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "42e54e1ecb0943e7b551e91a576623c6": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "DescriptionStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "dfb48ab2a8d246fea96de480973e4efe": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "8517a336c5e84ef3b2ccb902bbaf217a": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "state": {
            "_view_name": "HBoxView",
            "_dom_classes": [],
            "_model_name": "HBoxModel",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "box_style": "",
            "layout": "IPY_MODEL_48cd4c26605241928ce5c7813f4ab09e",
            "_model_module": "@jupyter-widgets/controls",
            "children": [
              "IPY_MODEL_2f9dd91f5ab9439e91385d56c185cd68",
              "IPY_MODEL_9e26fe277f544450a35e4a97beb22476"
            ]
          }
        },
        "48cd4c26605241928ce5c7813f4ab09e": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "2f9dd91f5ab9439e91385d56c185cd68": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "IntProgressModel",
          "state": {
            "_view_name": "ProgressView",
            "style": "IPY_MODEL_3f439cef173d48feb8a6c037c94bb189",
            "_dom_classes": [],
            "description": "",
            "_model_name": "IntProgressModel",
            "bar_style": "success",
            "max": 1,
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": 1,
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "orientation": "horizontal",
            "min": 0,
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_74867a7615c8417aaf652c57f3849ecb"
          }
        },
        "9e26fe277f544450a35e4a97beb22476": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "state": {
            "_view_name": "HTMLView",
            "style": "IPY_MODEL_60c66254625040cbaba3b9985fbd4f2c",
            "_dom_classes": [],
            "description": "",
            "_model_name": "HTMLModel",
            "placeholder": "​",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": "1654784it [00:00, 2166768.69it/s]",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_b95d4a18e7eb43b0b2d87f175fda006a"
          }
        },
        "3f439cef173d48feb8a6c037c94bb189": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "ProgressStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "bar_color": null,
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "74867a7615c8417aaf652c57f3849ecb": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "60c66254625040cbaba3b9985fbd4f2c": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "DescriptionStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "b95d4a18e7eb43b0b2d87f175fda006a": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "f1fecf8f57e74073a684b5acfe3471a0": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "state": {
            "_view_name": "HBoxView",
            "_dom_classes": [],
            "_model_name": "HBoxModel",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "box_style": "",
            "layout": "IPY_MODEL_51d43b79ed5548dd953f1f5c9e792126",
            "_model_module": "@jupyter-widgets/controls",
            "children": [
              "IPY_MODEL_f3087f2f7e6e47f0a9b4027f780fe580",
              "IPY_MODEL_5bb39855cbe24cfaadbceda206ff3a48"
            ]
          }
        },
        "51d43b79ed5548dd953f1f5c9e792126": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "f3087f2f7e6e47f0a9b4027f780fe580": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "IntProgressModel",
          "state": {
            "_view_name": "ProgressView",
            "style": "IPY_MODEL_7a0163ce7bc7418baf64b829e0122925",
            "_dom_classes": [],
            "description": "",
            "_model_name": "IntProgressModel",
            "bar_style": "success",
            "max": 1,
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": 1,
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "orientation": "horizontal",
            "min": 0,
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_c9746a5c895d42e396da5e76aeb5ba18"
          }
        },
        "5bb39855cbe24cfaadbceda206ff3a48": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "state": {
            "_view_name": "HTMLView",
            "style": "IPY_MODEL_63780e6d72a04c828740109d7eedc6de",
            "_dom_classes": [],
            "description": "",
            "_model_name": "HTMLModel",
            "placeholder": "​",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": "8192it [00:00, 46722.33it/s]",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_377284955382461d86386944718dd1bd"
          }
        },
        "7a0163ce7bc7418baf64b829e0122925": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "ProgressStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "bar_color": null,
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "c9746a5c895d42e396da5e76aeb5ba18": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "63780e6d72a04c828740109d7eedc6de": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "DescriptionStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "377284955382461d86386944718dd1bd": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        }
      }
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "xuZDvxoMNCXS"
      },
      "source": [
        "## **COMP5623 Artificial Intelligence**\n",
        "University of Leeds\n",
        "Spring 2019-2020\n",
        "\n",
        "\n",
        "The purpose of this notebook is to give you a general understanding of how to use the PyTorch Python package for writing, training and analysing neural networks. Only the key topics are covered, and many references are included to documentation and other helpful resources.\n",
        "\n",
        "\n",
        "\n",
        "---\n",
        "\n",
        "### **Introduction to PyTorch**\n",
        "\n",
        "\n",
        "Why PyTorch in this module instead of TensorFlow, Keras, Theano, etc.?\n",
        "\n",
        "- Simplicity but not oversimplified\n",
        "- API\n",
        "- Performance\n",
        "\n",
        "![why_pytorch.png](https://drive.google.com/uc?id=1EQqmbiKtXFVTcqGsxnIu_hqVy7vV1Lyp)\n",
        "\n",
        "Some real evidence that researchers are moving steadily towards PyTorch:\n",
        "\n",
        "https://thegradient.pub/state-of-ml-frameworks-2019-pytorch-dominates-research-tensorflow-dominates-industry/\n",
        "\n",
        "\n",
        "---\n",
        "\n",
        "\n",
        "### Some recommended resources\n",
        "\n",
        "- Pytorch 60-min Blitz Tutorial https://pytorch.org/tutorials/beginner/blitz/tensor_tutorial.html\n",
        "- PyTorch Deep Learning Hands-On by Sherin Thomas and Sudhanshu Passi\n",
        "- Stanford Spring 2019 CS231n Convolutional Neural Networks for Visual Recognition http://cs231n.stanford.edu/, particularly Lecture 6 on PyTorch.\n",
        "- \"A Beginner-Friendly Guide to PyTorch and How it Works from Scratch\" https://www.analyticsvidhya.com/blog/2019/09/introduction-to-pytorch-from-scratch/\n",
        "- The “Image classification (MNIST) using Convnets” example from the PyTorch Git repository (https://github.com/pytorch/examples)\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "---\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "As an overview, this notebook covers:\n",
        "\n",
        "1. Tensors\n",
        "2. Gradients\n",
        "3. Datasets\n",
        "4. Neural networks\n",
        "5. Training (+ training on a GPU)\n",
        "\n",
        "\n",
        "***Welcome to come to lab to work through this notebook and ask questions!***\n",
        "\n",
        "---\n",
        "\n",
        "### 1. Tensors"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "R6-zcPdENCXU",
        "colab": {}
      },
      "source": [
        "import torch"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "2C51jrpYNCXZ"
      },
      "source": [
        "A Tensor - the basic building block. Similar to NumPy’s ndarrays, with the addition being that Tensors can also be used on a GPU."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "M5SdlMccNCXa",
        "colab": {}
      },
      "source": [
        "x = torch.tensor([5.0, 3, 6.6, 1])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "XnvoFZKhNCXd",
        "outputId": "1d2d90a2-e199-4756-8b72-6500cf41ab8c",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "x"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([5.0000, 3.0000, 6.6000, 1.0000])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 3
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "Bad_SGELNCXi"
      },
      "source": [
        "NumPy-like behaviour for array operations - not a regular Python list."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "oiLAaev1NCXi",
        "outputId": "72be3d16-b20c-4135-8129-07993fc5bd9b",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "x + 1"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([6.0000, 4.0000, 7.6000, 2.0000])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 4
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "lB9hupOONCXm"
      },
      "source": [
        "PyTorch tensors can be on your CPU or GPU. You can explicitly copy it back and forth.  We will look into this more later in this notebook."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "53NXGS7XNCXn"
      },
      "source": [
        "### 2. Gradients\n",
        "\n",
        "PyTorch tensors are more powerful than NumPy ndarrays when we are interested in propagating gradients."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "LPSziGahNCXo"
      },
      "source": [
        "Neural networks are trained via two operations:\n",
        "\n",
        "- a forward pass\n",
        "- a backward pass\n",
        "\n",
        "Both the gradient, and forward and backward pass functions are attached to PyTorch's Tensor object.\n",
        "\n",
        "![gradients](https://drive.google.com/uc?id=1bJavTiS98fioAN4ipI82o_Mej4CTI23_)\n",
        "\n",
        "Slide 51, Backpropagation of Gradients, Lecture \"Image Classification using CNNs\"\n",
        "\n",
        "---\n",
        "\n",
        "\n",
        "Setting **require_grad=True** makes PyTorch track all the operations on that Tensor. When you finish the computation, you can call .backward() on it and the gradients are stored in the **.grad** attribute.\n",
        "\n",
        "- https://pytorch.org/tutorials/beginner/blitz/autograd_tutorial.html\n",
        "https://towardsdatascience.com/\n",
        "\n",
        "- https://towardsdatascience.com/getting-started-with-pytorch-part-1-understanding-how-automatic-differentiation-works-5008282073ec"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "Ttuc2O7_NCXq",
        "outputId": "504ee652-50ba-42eb-c17c-db064da09594",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "x = torch.tensor([4.0, 5.0, 6.0], requires_grad=True)\n",
        "x"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([4., 5., 6.], requires_grad=True)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 5
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "cefE-tNOajiJ"
      },
      "source": [
        "Does **x** have a grad_fn?"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "Ddij89zlal9N",
        "colab": {}
      },
      "source": [
        "x.grad_fn\n",
        "#这是啥阿？ None"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "ElaxL3rtNCXt",
        "colab": {}
      },
      "source": [
        "z = x + 2"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "SpVFdgplaoih",
        "outputId": "df5ed349-a1b6-4bda-e5d9-923eb9cf1ffe",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "z"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([6., 7., 8.], grad_fn=<AddBackward0>)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 8
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "Lzsn-dHJNCXx"
      },
      "source": [
        "To illustrate how powerful this can be, let's look at the computational graph from the example above. \n",
        "\n",
        "Consider first what this would look like in NumPy."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "S1uUN35zNCXy",
        "outputId": "5fc06d36-d982-4143-ac87-b053ce795a71",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "import numpy as np\n",
        "\n",
        "x = np.array([1.0, 2.0, 3.0])\n",
        "w = np.array([4.0, 5.0, 6.0])\n",
        "v = np.array([7.0, 8.0, 9.0])\n",
        "\n",
        "y = x * w\n",
        "y"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([ 4., 10., 18.])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 8
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "q6VQL9WPNCX8"
      },
      "source": [
        "We could compute the gradient for **w** manually using NumPy.\n",
        "\n",
        "![loss](https://drive.google.com/uc?id=1eFM0lRxRlbWXGgB5-0lU-SgUIAT08uny)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "NGDoUbciNCX9",
        "outputId": "002df32e-76e0-4ed3-8282-6ec5cbbc6653",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "grad_w = v * w\n",
        "\n",
        "print(\"grad_w:\", grad_w)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "grad_w: [28. 40. 54.]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "iLEVHuomNCYA"
      },
      "source": [
        "Now, build the same computational graph in PyTorch."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "kNGHDDVoNCYA",
        "outputId": "76574244-9113-47a1-f98c-665a40a39a52",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "w = torch.tensor((1.0,2.0,3.0), requires_grad=True)\n",
        "x = torch.tensor((4.0,5.0,6.0))\n",
        "v = torch.tensor((7.0,8.0,9.0))\n",
        "\n",
        "y = w * x\n",
        "print(y)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "tensor([ 4., 10., 18.], grad_fn=<MulBackward0>)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "oazbMokMXDb-"
      },
      "source": [
        "Now, with one function call on the output tensor:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "4igAW3ByNCYD",
        "colab": {}
      },
      "source": [
        "y.backward(v)\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "ibIb8JifNCYF"
      },
      "source": [
        "Now we can directly access the gradient on w, which has been calculated for us."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "djMwnFqqNCYG",
        "outputId": "057009b7-6322-4a8b-ec91-18e6ffa31025",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "w.grad \n",
        "#w.grad = x* v\n"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([28., 40., 54.])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 12
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "yriVb3QrNCYL"
      },
      "source": [
        "If you don't want to track gradients, you can put code inside a **with torch.no_grad()** block. This saves memory. "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "TtuIbtJSNCYM"
      },
      "source": [
        "### 3. Datasets\n",
        "### 3. Datasets\n",
        "\n",
        "We will only cover this briefly, as this code will be provided for you for the coursework dataset. It is helpful to know generally how it works.\n",
        "\n",
        "**Transforms** are common image transformations which can be chained together using Compose().\n",
        "\n",
        "https://pytorch.org/docs/stable/torchvision/transforms.html"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "zm3zlsBWRWH2",
        "colab": {}
      },
      "source": [
        "from torchvision import transforms"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "rzND3DXhNCYN",
        "colab": {}
      },
      "source": [
        "transform = transforms.Compose([\n",
        "    transforms.ToTensor(),\n",
        "    transforms.Normalize((0.5,), (0.5,))\n",
        "])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "tWtHP1q-NCYT"
      },
      "source": [
        "Certain commonly-used public datasets are available directly via PyTorch, through **torchvision.datasets**."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "7DhlOV2ANCYU",
        "colab": {}
      },
      "source": [
        "import torchvision"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "R5rJd9vMNCYX"
      },
      "source": [
        "Listing of all available datasets here: https://pytorch.org/docs/stable/torchvision/datasets.html"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "x3koTaOJNCYY",
        "outputId": "82fd776a-0889-4ddf-d266-a63e8ae7578d",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 383,
          "referenced_widgets": [
            "4d7dab5d56d34b598b514c6a3a98b5e5",
            "6097a8fbb58f4013b41194a5ae544656",
            "ed624df9e1cf49ea8c864581851a45d7",
            "89a798fcb3fb4364b96c1de26bbaff34",
            "d82d1936f55344238f00f226f86caae1",
            "bc3f0f777f034019982bfbb1a1b61330",
            "be61d9e8318d4ec9b42bc1ae8ba7a591",
            "17e0eea786cb425c91c9d16189ee6753",
            "26e8e4195a054c4e8245560027224ef1",
            "ea0f7ffaa0a8406ba88674b69c4083c1",
            "1e7e8c393853471abfcf93336e11995f",
            "247075d916c643de8452764a93572a56",
            "de6898f868244050bdecb70aa8a0daa1",
            "7f49c2ed443a4c0f80bc8ea216b50269",
            "42e54e1ecb0943e7b551e91a576623c6",
            "dfb48ab2a8d246fea96de480973e4efe",
            "8517a336c5e84ef3b2ccb902bbaf217a",
            "48cd4c26605241928ce5c7813f4ab09e",
            "2f9dd91f5ab9439e91385d56c185cd68",
            "9e26fe277f544450a35e4a97beb22476",
            "3f439cef173d48feb8a6c037c94bb189",
            "74867a7615c8417aaf652c57f3849ecb",
            "60c66254625040cbaba3b9985fbd4f2c",
            "b95d4a18e7eb43b0b2d87f175fda006a",
            "f1fecf8f57e74073a684b5acfe3471a0",
            "51d43b79ed5548dd953f1f5c9e792126",
            "f3087f2f7e6e47f0a9b4027f780fe580",
            "5bb39855cbe24cfaadbceda206ff3a48",
            "7a0163ce7bc7418baf64b829e0122925",
            "c9746a5c895d42e396da5e76aeb5ba18",
            "63780e6d72a04c828740109d7eedc6de",
            "377284955382461d86386944718dd1bd"
          ]
        }
      },
      "source": [
        "# Load the datasets from PyTorch\n",
        "train_set = torchvision.datasets.MNIST(\n",
        "    root='./data',\n",
        "    train=True,\n",
        "    download=True,\n",
        "    transform=transform\n",
        ")\n",
        "\n",
        "test_set = torchvision.datasets.MNIST(\n",
        "    root='./data',\n",
        "    train=False,\n",
        "    download=True,\n",
        "    transform=transform\n",
        ")"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Downloading http://yann.lecun.com/exdb/mnist/train-images-idx3-ubyte.gz to ./data/MNIST/raw/train-images-idx3-ubyte.gz\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "4d7dab5d56d34b598b514c6a3a98b5e5",
              "version_minor": 0,
              "version_major": 2
            },
            "text/plain": [
              "HBox(children=(IntProgress(value=1, bar_style='info', max=1), HTML(value='')))"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "\n",
            "Extracting ./data/MNIST/raw/train-images-idx3-ubyte.gz to ./data/MNIST/raw\n",
            "Downloading http://yann.lecun.com/exdb/mnist/train-labels-idx1-ubyte.gz to ./data/MNIST/raw/train-labels-idx1-ubyte.gz\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "26e8e4195a054c4e8245560027224ef1",
              "version_minor": 0,
              "version_major": 2
            },
            "text/plain": [
              "HBox(children=(IntProgress(value=1, bar_style='info', max=1), HTML(value='')))"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "\n",
            "Extracting ./data/MNIST/raw/train-labels-idx1-ubyte.gz to ./data/MNIST/raw\n",
            "Downloading http://yann.lecun.com/exdb/mnist/t10k-images-idx3-ubyte.gz to ./data/MNIST/raw/t10k-images-idx3-ubyte.gz\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "8517a336c5e84ef3b2ccb902bbaf217a",
              "version_minor": 0,
              "version_major": 2
            },
            "text/plain": [
              "HBox(children=(IntProgress(value=1, bar_style='info', max=1), HTML(value='')))"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "\n",
            "Extracting ./data/MNIST/raw/t10k-images-idx3-ubyte.gz to ./data/MNIST/raw\n",
            "Downloading http://yann.lecun.com/exdb/mnist/t10k-labels-idx1-ubyte.gz to ./data/MNIST/raw/t10k-labels-idx1-ubyte.gz\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "f1fecf8f57e74073a684b5acfe3471a0",
              "version_minor": 0,
              "version_major": 2
            },
            "text/plain": [
              "HBox(children=(IntProgress(value=1, bar_style='info', max=1), HTML(value='')))"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "\n",
            "Extracting ./data/MNIST/raw/t10k-labels-idx1-ubyte.gz to ./data/MNIST/raw\n",
            "Processing...\n",
            "Done!\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "_teqQ2OBNCYd"
      },
      "source": [
        "If you are using a dataset not listed, you can create a custom Dataset class which will inherit the PyTorch parent Dataset class. It can then be loaded the same way."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "Vk6kzSlTNCYf"
      },
      "source": [
        "Data loaders are provided by **torch.utils.data** and help for easy iteration over datasets. \n",
        "\n",
        "https://pytorch.org/tutorials/beginner/data_loading_tutorial.html"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "zfFcsImqNCYg",
        "colab": {}
      },
      "source": [
        "train_loader = torch.utils.data.DataLoader(\n",
        "    train_set,\n",
        "    batch_size=16,\n",
        "    shuffle=True,\n",
        "    num_workers=2\n",
        ")\n",
        "\n",
        "\n",
        "test_loader = torch.utils.data.DataLoader(\n",
        "    test_set,\n",
        "    batch_size=24, # Forward pass only so batch size can be larger 一批次24个\n",
        "    shuffle=False,\n",
        "    num_workers=2\n",
        ")\n",
        "\n",
        "classes = np.arange(0, 10)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "-Xd4GKasNCYi"
      },
      "source": [
        "To iterate over the test set, one batch at a time, we do the following:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "BOyw1HQANCYk",
        "outputId": "63c04e58-744f-4cef-90a3-53587c078333",
        "scrolled": true,
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "# 24 images at a time\n",
        "for i, data in enumerate(test_loader, 0):\n",
        "    images, labels = data\n",
        "    print(\"Batch\", i, \"size:\", len(images))\n",
        "    \n",
        "    # Do stuff with the images and labels.\n",
        "    break # Terrible programming. Just for illustration."
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Batch 0 size: 24\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "dRHG-ADrNCYm"
      },
      "source": [
        "Note that the length of a loader is the *number of batches*, not the total number of images."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "l61vr7HANCYn",
        "outputId": "9f52ad1d-197f-42ea-efbb-b48b056fb06b",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "len(test_loader)\n",
        "#len(train_loader)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "417"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 11
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "kFl1UKe4NCYq"
      },
      "source": [
        "If you want to look at the images in the set one by one, you can define a loader with batch_size of 1 and iterate over it using an iterator."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "ram2KLh0NCYr",
        "colab": {}
      },
      "source": [
        "extra_loader = torch.utils.data.DataLoader(\n",
        "    test_set,\n",
        "    batch_size=1,\n",
        "    shuffle=False,\n",
        ")\n",
        "\n",
        "iterator = iter(extra_loader)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "qiWYqK9YNCYu",
        "colab": {}
      },
      "source": [
        "# iterator.next()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "Iv39kevINCYx"
      },
      "source": [
        "### 4. Neural networks\n",
        "\n",
        "There are two steps:\n",
        "\n",
        "1. Define the network.\n",
        "2. Specify a loss function and optimizer.\n",
        "\n",
        "First, we recommend defining the network as a class. The **nn** or Neural Network part of PyTorch contains all the classes and functions related to defining a neural network."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "lU997161NCYy",
        "colab": {}
      },
      "source": [
        "import torch.nn as nn"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "RNKjJtQcNCY2"
      },
      "source": [
        "Let's build a simple linear classifier.\n",
        "\n",
        "All networks should inherit from the **nn.Module** parent class: https://pytorch.org/docs/stable/nn.html#module\n",
        "\n",
        "**nn.Module** stores learnable weights and state.\n",
        "\n",
        "You will always need two functions:\n",
        "\n",
        "1. __init__, which will be called the moment you instantiate the class.\n",
        "\n",
        "2. **forward()** function which will be called during training.\n",
        "\n",
        "The documentation for all the nn.Module layers supported by PyTorch is here https://pytorch.org/docs/stable/nn.html, including:\n",
        "\n",
        "- Conv2D\n",
        "- MaxPool2D\n",
        "- ReLU\n",
        "- Dropout2D\n",
        "- many, many more.\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "oeXFwo_NNCY2",
        "colab": {}
      },
      "source": [
        "class LinearClassifier(nn.Module):\n",
        "    \n",
        "    def __init__(self, num_classes=10):\n",
        "        # Calls __init__() on the parent class, which is nn.Module\n",
        "        super(LinearClassifier, self).__init__()\n",
        "        \n",
        "        # Define each layer of the network as a class variable\n",
        "        # fc1 stands for first fully-connected layer\n",
        "        self.fc1 = nn.Linear(28 * 28, num_classes)\n",
        "        #啥意思阿。。\n",
        "        \n",
        "    def forward(self, x):\n",
        "        out = x.reshape(x.size(0), -1) # TODO what does this do? Why do we need it?\n",
        "        out = self.fc1(out)\n",
        "        return out"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "RzEDnstBW8cM"
      },
      "source": [
        "You can optionally seed the Random Number Generator across all devices for testing purposes."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "MaNZ5hzdXHly",
        "outputId": "a86582d0-7b31-41db-a3dd-15e1044fa230",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "torch.manual_seed(0)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<torch._C.Generator at 0x7f3ad1db1d30>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 16
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "XK82t7xsNCY5"
      },
      "source": [
        "We can now create a classifier instance."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "9c8chSInNCY7",
        "outputId": "59c59c13-a19c-4f8f-f637-aa09b123544f",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 68
        }
      },
      "source": [
        "model = LinearClassifier()\n",
        "model"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "LinearClassifier(\n",
              "  (fc1): Linear(in_features=784, out_features=10, bias=True)\n",
              ")"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 17
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "7XGVFLV_NCZA"
      },
      "source": [
        "The layers can be accessed directly and so can their parameters!"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "O6t708i3NCZB",
        "outputId": "e78e0b7e-4bcf-41ac-af88-f8f6d886b95b",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "model.fc1"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Linear(in_features=784, out_features=10, bias=True)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 18
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "MYXIDYrZXl0Q",
        "outputId": "b63ee904-fa57-49c3-cdb6-45819c61e83d",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 170
        }
      },
      "source": [
        "model.fc1.weight"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Parameter containing:\n",
              "tensor([[-0.0003,  0.0192, -0.0294,  ...,  0.0219,  0.0037,  0.0021],\n",
              "        [-0.0198, -0.0150, -0.0104,  ..., -0.0203, -0.0060, -0.0299],\n",
              "        [-0.0201,  0.0149, -0.0333,  ..., -0.0203,  0.0012,  0.0080],\n",
              "        ...,\n",
              "        [ 0.0237,  0.0103, -0.0219,  ...,  0.0088, -0.0009,  0.0009],\n",
              "        [ 0.0144, -0.0336, -0.0346,  ..., -0.0222, -0.0025, -0.0138],\n",
              "        [-0.0196, -0.0118,  0.0230,  ..., -0.0202,  0.0172,  0.0355]],\n",
              "       requires_grad=True)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 19
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "z0ULZhy7NCZF"
      },
      "source": [
        "Now define the loss and optimiser.\n",
        "\n",
        "\n",
        "- Optimisers https://pytorch.org/docs/stable/optim.html\n",
        "- Loss functions https://pytorch.org/docs/stable/nn.html#loss-functions"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "3Tl2gtwrRzbF",
        "colab": {}
      },
      "source": [
        "from torch import optim"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "MUv3eFyZNCZG",
        "colab": {}
      },
      "source": [
        "criterion = nn.CrossEntropyLoss()\n",
        "\n",
        "# Stochastic gradient descent\n",
        "optimizer = optim.SGD(model.parameters(), lr=0.001, momentum=0.9)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "4drUKnKUNCZN"
      },
      "source": [
        "### 5. Training"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "AZKUwo9GNCZO"
      },
      "source": [
        "During training, we iterate over a fixed number of epochs. An epoch is *one complete iteration through the entire training set.* \n",
        "\n",
        "You can either fix the number of epochs to train for, or can dynamically determine when to stop training. Alternately, you can checkpoint frequently over a large fixed number of epochs and then determine the best model later. \n",
        "\n",
        "It is highly advised to use a validation set (not shown here)."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "aeT50Y6vNCZP",
        "colab": {}
      },
      "source": [
        "import timeit"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "Bebl4o0eNCZU",
        "colab": {}
      },
      "source": [
        "def train_model_epochs(num_epochs):\n",
        "    \"\"\" Trains the model for a given number of epochs on the training set. \"\"\"\n",
        "    for epoch in range(num_epochs):\n",
        "\n",
        "        running_loss = 0.0\n",
        "        for i, data in enumerate(train_loader, 0):\n",
        "            images, labels = data\n",
        "\n",
        "            # Zero the parameter gradients means to reset them from\n",
        "            # any previous values. By default, gradients accumulate!\n",
        "            optimizer.zero_grad()\n",
        "\n",
        "            # Passing inputs to the model calls the forward() function of\n",
        "            # the Module class, and the outputs value contains the return value\n",
        "            # of forward()\n",
        "            outputs = model(images)\n",
        "\n",
        "            # Compute the loss based on the true labels\n",
        "            loss = criterion(outputs, labels)\n",
        "\n",
        "            # Backpropagate the error with respect to the loss\n",
        "            loss.backward()\n",
        "\n",
        "            # Updates the parameters based on current gradients and update rule;\n",
        "            # in this case, defined by SGD()\n",
        "            optimizer.step()\n",
        "\n",
        "            # Print our loss\n",
        "            running_loss += loss.item()\n",
        "            if i % 1000 == 999:    # print every 1000 mini-batches\n",
        "                print('Epoch / Batch [%d / %d] - Loss: %.3f' %\n",
        "                      (epoch + 1, i + 1, running_loss / 1000))\n",
        "                running_loss = 0.0"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "qOQvKBUWNCZX"
      },
      "source": [
        "Train and time."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "7T5iAlujNCZY",
        "outputId": "2c893400-e517-4731-aadc-a85aa8afe390",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 323
        }
      },
      "source": [
        "# train_model_epochs(num_epochs)\n",
        "\n",
        "cpu_train_time = timeit.timeit(\n",
        "    \"train_model_epochs(num_epochs)\",\n",
        "    setup=\"num_epochs=6\",\n",
        "    number=1,\n",
        "    globals=globals(),\n",
        ")"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch / Batch [1 / 1000] - Loss: 0.632\n",
            "Epoch / Batch [1 / 2000] - Loss: 0.395\n",
            "Epoch / Batch [1 / 3000] - Loss: 0.349\n",
            "Epoch / Batch [2 / 1000] - Loss: 0.342\n",
            "Epoch / Batch [2 / 2000] - Loss: 0.331\n",
            "Epoch / Batch [2 / 3000] - Loss: 0.310\n",
            "Epoch / Batch [3 / 1000] - Loss: 0.309\n",
            "Epoch / Batch [3 / 2000] - Loss: 0.311\n",
            "Epoch / Batch [3 / 3000] - Loss: 0.304\n",
            "Epoch / Batch [4 / 1000] - Loss: 0.286\n",
            "Epoch / Batch [4 / 2000] - Loss: 0.303\n",
            "Epoch / Batch [4 / 3000] - Loss: 0.301\n",
            "Epoch / Batch [5 / 1000] - Loss: 0.286\n",
            "Epoch / Batch [5 / 2000] - Loss: 0.298\n",
            "Epoch / Batch [5 / 3000] - Loss: 0.296\n",
            "Epoch / Batch [6 / 1000] - Loss: 0.288\n",
            "Epoch / Batch [6 / 2000] - Loss: 0.277\n",
            "Epoch / Batch [6 / 3000] - Loss: 0.295\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "Qsug7r1wNCZd",
        "outputId": "27ccd1a0-8832-45db-92ec-6dbad576d09c",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "cpu_train_time"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "121.73551390100005"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 30
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "TE_n0h8rNCZg"
      },
      "source": [
        "How does the classifier perform on the test set?"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "O4mUuwllNCZh",
        "outputId": "120ad4ea-9d66-46d6-c632-f9026c469260",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "correct = 0\n",
        "total = 0\n",
        "\n",
        "# Why don't we need gradients? What happens if we do include gradients?\n",
        "with torch.no_grad():\n",
        "    \n",
        "    # Iterate over the test set\n",
        "    for data in test_loader:\n",
        "        images, labels = data\n",
        "        \n",
        "        outputs = model(images)\n",
        "        \n",
        "        # torch.max is an argmax operation\n",
        "        _, predicted = torch.max(outputs.data, 1)\n",
        "        \n",
        "        total += labels.size(0)\n",
        "        correct += (predicted == labels).sum().item()\n",
        "\n",
        "print('Accuracy of the network on the test images: %d %%' % (100 * correct / total))"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Accuracy of the network on the test images: 92 %\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "Coz8pxUANCZj"
      },
      "source": [
        "You can save and reload models. Torch models are checkpoint files.\n",
        "\n",
        "https://pytorch.org/tutorials/beginner/saving_loading_models.html"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "IZlfdUZTNCZj",
        "colab": {}
      },
      "source": [
        "torch.save(model, './my_mnist_model.pt') "
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "u7EJ12-hNCZq"
      },
      "source": [
        "Accuracy and confusion matrix."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "4m7qvfYnNCZr",
        "colab": {}
      },
      "source": [
        "from sklearn.metrics import confusion_matrix\n",
        "import matplotlib.pyplot as plt"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "jp872eJeNCZx",
        "colab": {}
      },
      "source": [
        "cm = confusion_matrix(labels, predicted)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "h9_DcVx_NCZ1",
        "outputId": "40fcca5c-ec9a-4595-df3f-535e1a4a5a5e",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 187
        }
      },
      "source": [
        "cm"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[1, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
              "       [0, 2, 0, 0, 0, 0, 0, 0, 0, 0],\n",
              "       [0, 0, 2, 0, 0, 0, 0, 0, 0, 0],\n",
              "       [0, 0, 0, 1, 0, 0, 0, 0, 1, 0],\n",
              "       [0, 0, 0, 0, 2, 0, 0, 0, 0, 0],\n",
              "       [0, 0, 0, 0, 0, 2, 0, 0, 0, 0],\n",
              "       [0, 0, 0, 0, 0, 0, 2, 0, 0, 0],\n",
              "       [0, 0, 0, 0, 0, 0, 0, 1, 0, 0],\n",
              "       [0, 0, 0, 0, 0, 0, 0, 0, 1, 0],\n",
              "       [0, 0, 0, 0, 0, 0, 0, 0, 0, 1]])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 34
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "kzAO6TKKNCZ7"
      },
      "source": [
        "Let's make it easier for viewing."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "KV8zssFoNCZ8",
        "colab": {}
      },
      "source": [
        "import itertools\n",
        "\n",
        "def plot_confusion_matrix(cm,\n",
        "                          classes,\n",
        "                          normalize=False,\n",
        "                          title='Confusion matrix',\n",
        "                          cmap=plt.cm.Blues):\n",
        "    \"\"\"\n",
        "    This function prints and plots the confusion matrix very prettily.\n",
        "    Normalization can be applied by setting `normalize=True`.\n",
        "    \"\"\"\n",
        "    if normalize:\n",
        "        cm = cm.astype('float') / cm.sum(axis=1)[:, np.newaxis]\n",
        "        print(\"Normalized confusion matrix\")\n",
        "    else:\n",
        "        print('Confusion matrix, without normalization')\n",
        "\n",
        "    plt.imshow(cm, interpolation='nearest', cmap=cmap)\n",
        "    plt.title(title)\n",
        "\n",
        "    # Specify the tick marks and axis text\n",
        "    tick_marks = np.arange(len(classes))\n",
        "    plt.xticks(tick_marks, classes, rotation=90)\n",
        "    plt.yticks(tick_marks, classes)\n",
        "\n",
        "    # The data formatting\n",
        "    fmt = '.2f' if normalize else 'd't\n",
        "    thresh = cm.max() / 2.\n",
        "    \n",
        "    # Print the text of the matrix, adjusting text colour for display\n",
        "    for i, j in itertools.product(range(cm.shape[0]), range(cm.shape[1])):\n",
        "        plt.text(j, i, format(cm[i, j], fmt),\n",
        "                 horizontalalignment=\"center\",\n",
        "                 color=\"white\" if cm[i, j] > thresh else \"black\")\n",
        "\n",
        "    plt.ylabel('True label')\n",
        "    plt.xlabel('Predicted label')\n",
        "    plt.tight_layout()\n",
        "    plt.show()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "ytZnFKgZNCaB",
        "outputId": "1e38b17f-8f20-41ef-b8f4-22330886a665",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 314
        }
      },
      "source": [
        "plot_confusion_matrix(cm, classes)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Confusion matrix, without normalization\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAQgAAAEYCAYAAACgIGhkAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz\nAAALEgAACxIB0t1+/AAAADh0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uMy4xLjIsIGh0\ndHA6Ly9tYXRwbG90bGliLm9yZy8li6FKAAAeHElEQVR4nO3deZwdZZn28d+VhEBCQkATliQgm4AJ\nDpEkwAsuEdEXIQIzLoCMC2Lc2CKiouCLOsO8jkZcBmYkDoMokiDbgCAkKG4gSyAESEhYA5JAIKhA\nCGuae/6oauYQurpP+tTT3U/6+n4+55M+59S56unq7jt16jx1lyICM7OODOjtAZhZ3+UCYWaVXCDM\nrJILhJlVcoEws0ouEGZWyQViPSZpiKRfSnpK0oUt5BwhaW6dY+stkt4m6e7eHkcu5HkQvU/Sh4ET\ngF2AVcAC4LSIuK7F3I8AxwJ7R8Salgfax0kK4I0RcV9vj2V94T2IXibpBOD7wL8AWwDbAP8OHFxD\n/BuAe/pDcWiGpEG9PYbsRIRvvXQDRgDPAB/sZJkNKQrII+Xt+8CG5XNTgGXAF4DHgUeBI8vnvgG8\nCLxUruMo4OvAeQ3Z2wIBDCrvfxx4gGIvZilwRMPj1zW8bm9gHvBU+e/eDc/9Dvgn4PoyZy4wsuJ7\nax//lxrGfwhwAHAP8Ffgqw3L7wHcADxZLnsGMLh87g/l97K6/H4Pbcj/MrAC+Fn7Y+VrdijXsXt5\nfzSwEpjS278bfeXW6wPozzdgf2BN+x9oxTLfBG4ENgdGAX8C/ql8bkr5+m8CG5R/WM8Cm5XPr10Q\nKgsEsDHwNLBz+dxWwPjy61cKBPA64G/AR8rXHV7ef335/O+A+4GdgCHl/W9VfG/t4/9/5finlX+g\n5wPDgfHAc8B25fITgb3K9W4LLAamN+QFsGMH+f9KUWiHNBaIcplpwF3AUGAOMKO3fy/60s1vMXrX\n64EnovO3AEcA34yIxyNiJcWewUcann+pfP6liPgVxf+eO3dzPC8Du0oaEhGPRsSiDpY5ELg3In4W\nEWsiYhawBHhfwzLnRMQ9EfEc8AtgQifrfInieMtLwGxgJPCDiFhVrv8uYDeAiLg1Im4s1/sgcBbw\njia+p1Mj4oVyPK8SET8G7gNuoiiKJ3eR16+4QPSuvwAju3hvPBp4qOH+Q+Vjr2SsVWCeBYat60Ai\nYjXFbvlngEclXSlplybG0z6mMQ33V6zDeP4SEW3l1+1/wI81PP9c++sl7STpCkkrJD1NcdxmZCfZ\nACsj4vkulvkxsCvwbxHxQhfL9isuEL3rBuAFivfdVR6hONjYbpvyse5YTbEr3W7LxicjYk5EvJvi\nf9IlFH84XY2nfUzLuzmmdfEfFON6Y0RsAnwVUBev6fRjOknDKI7rnA18XdLr6hjo+sIFohdFxFMU\n77/PlHSIpKGSNpD0XknfLhebBZwiaZSkkeXy53VzlQuAt0vaRtII4CvtT0jaQtLBkjamKFrPUOye\nr+1XwE6SPixpkKRDgXHAFd0c07oYTnGc5Jly7+azaz3/GLD9Omb+ALglIj4JXAn8qOVRrkdcIHpZ\nRHyXYg7EKRQH6B4GjgH+u1zkn4FbgDuAO4H55WPdWdc1wAVl1q28+o96QDmORyiO7L+D1/4BEhF/\nAaZSfHLyF4pPIKZGxBPdGdM6OhH4MMWnIz+m+F4afR04V9KTkj7UVZikgykOFLd/nycAu0s6orYR\nZ84TpcyskvcgzKySC4SZVXKBMLNKLhBmVqlPnbwyZJPNYvjmY7pecB1tPWKj2jPN1icPPfQgTzzx\nxGvmlPSpAjF88zF88Nu/qD33uweNqz3TbH2yz56TOnzcbzHMrJILhJlVyq5AXHvmKZxz5NuYPb2O\nfiqvNnfO1fzd+J0Zv8uOfOfb33Juzbkps3PLTZldZ252BWKXKYcw9Wtn1Z7b1tbG9OOO5rJfXsVt\nd9zFhbNnsfiuu5xbU27K7NxyU2bXnZtdgRg9fhIbDhtRe+68m29mhx12ZLvtt2fw4MF88NDDuOKX\nlzm3ptyU2bnlpsyuOze7ApHKI48sZ+zYrV+5P2bMWJYvb/0MZuemz84tN2V23blJC4Sk/SXdLek+\nSSelXJeZ1S9ZgZA0EDgTeC9Fv4DDJfXZCQmjR49h2bKHX7m/fPkyxoxpfdKWc9Nn55abMrvu3JR7\nEHsA90XEAxHxIkW/wfo/eqjJpMmTue++e3lw6VJefPFFLrxgNgdOPci5NeWmzM4tN2V23bkpZ1KO\noWh+0m4ZsGeroXNPP5FHFs3j+VVPcu60fZl86NGM2+/9rcYyaNAgvveDM3jfgf+XtrY2PvbxTzBu\n/Hjn1pSbMju33JTZdecmaxgj6QPA/mUrr/arPO0ZEcestdyngE8BDBu51cSPnvXr2sfiqdZmndtn\nz0nceustrzkXI+VbjOXA1g33x9JBY9OImBkRkyJi0pAR7hdq1pekLBDzgDdK2k7SYOAw4PKE6zOz\nmiU7BhERayQdQ3G1ooHAf1VciMXM+qikp3uXV3r6Vcp1mFk6nklpZpVcIMyskguEmVVygTCzSn2q\nJ+XWIzZKMqlps8nHdL1QN/1t3hnJss16m/cgzKySC4SZVXKBMLNKLhBmVskFwswqZVcgUrUKH7vF\nplw98zjmX3wyt150MkcfPqW27Bzam/dEbsrs3HJTZteZm6wfRHdMnDgprr/plsrn29raePO4nbjy\nqmsYM3Ysb91rMueeN4s3jev8o9FmPubccuQmbDlyExYsWcawoRvyp/O/zIdOmMmSB1Z0+rquPubs\n7pi7kltujmPuT9uiN/pB1C5lG/IVTzzNgiXLAHjm2RdYsnQFo0dt2nJuLu3NU+emzM4tN2V2v257\nn7INeaNttnodE3Yey7yFD7aclUt789S5KbNzy02ZnU3be0n/JelxSQtTrSOFjYcMZtaMT/LFGRez\navXzvT0cs16Vcg/iJ8D+dQambEMOMGjQAGbNmMYFV93CZdfeXktmLu3NU+emzM4tN2V2Nm3vI+IP\nwF/rzEzZhhzgR6cewd1LV/DD866tLTOX9uapc1Nm55abMjuntvdNaexqvfU223S6bMo25HtP2J4j\npu7Jnfcs58bZxUXATj3jcuZc19oFVXNpb546N2V2brkps7Npew8gaVvgiojYtZnlu/qYs7t8NqdZ\n59aLjznNrGe5QJhZpZQfc84CbgB2lrRM0lGp1mVmaaS8LsbhqbLNrGf4LYaZVXKBMLNKLhBmVskF\nwswq9fpMyp6QcjJTqklYnoBlfYH3IMyskguEmVVygTCzSi4QZlYpuwKRW5dhd8vumezcclNmu6t1\nH+oy3NWnGO6Wne+Y+9O2WC9O986xy7C7ZafPzi03Zba7WmfWZbhRf+6WnTI7t9yU2Tl1td5a0m8l\n3SVpkaTjU60rB+6WbTlKOZNyDfCFiJgvaThwq6RrIqLbTR5z7DIM7padOju33JTZOXW1fjQi5pdf\nrwIWAy1tgRy7DIO7ZafOzi03ZXaWXa3L5rVvAW7q4Lk+0dU6Vba7ZafPzi03ZXZWXa0BJA0Dfg+c\nFhGXdLZsqq7WKflkLVsf9MrHnJI2AC4Gft5VcTCzviflpxgCzgYWR8TpqdZjZumk3IPYB/gIsK+k\nBeXtgITrM7OapexqfR3wmvc0ZpaPrGZSmlnPcoEws0ouEGZWyQXCzCr1i67WKaWa0PSFy1ubadmZ\n7x7Uej8D69z68vPzHoSZVXKBMLNKLhBmVskFwswqZVcg+nuX4UbXnnkK5xz5NmZPP7i2TPA27onc\nVD87qHfMWRWItrY2ph93NJf98ipuu+MuLpw9i8V31XO0OFV2yjHvMuUQpn7trFqy2nkbp8+FND87\nqH/MWRUIdxl+tdHjJ7HhsBG1ZLXzNk6fC2l+duCu1v2+y3Bq3sbpc1PKqav1RpJulnR72dX6G6nW\nZWZppJxJ+QKwb0Q8U3aWuk7SVRFxY3cD3WU4PW/j9Lkp5dTVOiLimfLuBuWtpQaY7jKcnrdx+tyU\nsupqLWkgcCuwI3BmRPS7rtYpxzz39BN5ZNE8nl/1JOdO25fJhx7NuP3e32fHm9s2zu1nBxl2tQaQ\ntClwKXBsRCysWi7HrtaprC8n+/RXuf38evXivRHxJPBbYP+eWJ+Z1SPlpxijyj0HJA0B3g0sSbU+\nM6tfymMQWwHnlschBgC/iIgrEq7PzGqWsqv1HRSX2zOzTGU1k9LMepYLhJlVcoEws0ouEGZWyQXC\nzCpVfoohaZPOXhgRT9c/HGuXcrbjZpOPSZKb6hIAOVpfZqt29jHnIoqTqxqnX7bfD6DzEyfMLHuV\nBSIitq56zsz6h6aOQUg6TNJXy6/HSpqYdlhm1hd0WSAknQG8E/hI+dCzwI9SDsrM+oZm9iD2johP\nA88DRMRfgcFJR9UJt2RPmzt2i025euZxzL/4ZG696GSOPnxKLbntctoWKXNTZvd02/uXJA2g7AYl\n6fXAyy2ttZvckj197pq2lznp9EvY/f2n8Y6PzuDTh76dXbbfsuVcyG9b+PetuQJxJnAxMKpsPHsd\n8K/dXmML3JI9fe6KJ55mwZJlADzz7AssWbqC0aM2bTkX8tsW/n1rokBExE+BU4AZwF+BD0bE7G6v\nsQVuyZ4+t9E2W72OCTuPZd7CB2vJy21b+Pet+ZmUA4GXgBfX4TVA0ZdS0m2S3AsiIxsPGcysGZ/k\nizMuZtXq53t7ONZLmvkU42RgFjAaGAucL+kr67CO44HF3Rveq7kle/pcgEGDBjBrxjQuuOoWLrv2\n9loyIb9t4d+35vYGPgpMjohTIuJkYA/g482ESxoLHAj8Z7dH2MAt2dPnAvzo1CO4e+kKfnjetbXk\ntcttW/j3rbmOUo+utdyg8rFmfB/4EjC8agG3ve9buXtP2J4jpu7Jnfcs58bZJwFw6hmXM+e61o+w\n57Yt/PvWSdt7Sd+j+GhzW2AyMKe8/x5gXkR8oNNgaSpwQER8TtIU4MSImNrZa9z2vmf4ZC1bW1Xb\n+872INqvX7EIuLLh8WYvnbcPcJCkA4CNgE0knRcR/9jk682sl3V2stbZrQRHxFeArwA07EG4OJhl\npMtjEJJ2AE4DxlHsCQAQETslHJeZ9QHNfIrxE+Acij4Q7wV+AVywLiuJiN91dfzBzPqeZgrE0IiY\nAxAR90fEKRSFwszWc818zPlCebLW/ZI+Ayynk48tzWz90UyB+DywMXAcxbGIEcAnUg7KzPqGLgtE\nRNxUfrmK/20aY2b9QGddrS+l7AHRkYj4hyQjsuRSTWjyBKz1T2d7EP6pmPVznU2U+k1PDsTM+h5f\nWcvMKrlAmFmlpguEpA1TDqRZ/b3LcM65KTtm57YtUmb3aFdrSXtIuhO4t7y/m6R/a2mt3eQuw/nm\nQrqO2Tlui1zG3MwexA+BqcBfACLidooL6fQ4dxnONxfSdczOcVvkMuZmCsSAiHhorcfaur3GFrjL\ncL65a6uzY3aO2yKXMTcz1fphSXsAIWkgcCxwTzPhkh6kmIHZBqyJiEndHaitP9wxOx/NFIjPUrzN\n2AZ4DPh1+Viz3hkRT3RjbK/hLsP55rZL0TE7x22Ry5ibuXDO4xFxWESMLG+H1fUHv67cZTjf3HYp\nOmbnuC1yGXMzHaV+TAfnZETEp5rID2CupADOioiZHeS7q3U/yIV0HbNz3Ba5jLmyq/UrC0iHNtzd\nCPh74OGIOLbLcGlMRCyXtDlwDXBsRPyhanl3tc6bT9bKV3e6WgMQEa9qLyfpZxQX8O1SRCwv/328\nPDt0D6CyQJhZ39KdqdbbAVt0tZCkjSUNb/+a4noaCzt/lZn1Jc0cg/gb/3sMYgDFFb5PaiJ7C+BS\nSe3rOT8iru7mOM2sF3RaIFT8de9G0YcS4OXo6qBFKSIeKF9rZpnq9C1GWQx+FRFt5a2p4mBm64dm\njkEskPSW5CMxsz6ns56UgyJiDfAWYJ6k+4HVFBfQiYjYvYfGaGa9pLNjEDcDuwP1TaMzs6x0ViAE\nxdW0emgslrncumWDJ2F1pbMCMUrSCVVPRsTpCcZjZn1IZwViIDCMck/CzPqfzgrEoxHxzR4biZn1\nOZ19zOk9B7N+rrMC8a4eG8U66O9dhnPOTZWdY7fslNl15nZ5undP6up077a2Nt48bieuvOoaxowd\ny1v3msy5583iTePGtbzuVNnObT27q08xthy5CVuO3IQFS5YxbOiG/On8L/OhE2ay5IEVXY6ps08x\n+uK2SJVbdbp3VhfOcZfhfHNTZufWLTtldm90te4z3GU439zU2e1y6JadMrvu3KQFQtKmki6StETS\nYkn/J+X6rH9zt+z6NdPVuhU/AK6OiA9IGgwMbSXMXYbzzU2dnVO37JTZPd7VurskjQDeDpwNEBEv\nRsSTrWS6y3C+uamzc+qWnTK7x7tat2A7YCVwjqTdgFuB4yNideNC7mrdP3JTZufWLTtldo93te52\nsDQJuBHYJyJukvQD4OmI+FrVa9zV2jrik7XS642POZcByyLipvL+RRSnj5tZJpIViIhYQXFdz53L\nh94F1HPtdDPrEak/xTgW+Hn5CcYDwJGJ12dmNUpaICJiAeAreptlKquZlGbWs1wgzKySC4SZVXKB\nMLNKLhBmVin1x5xmLUs52/ELl6eZmvPdg1pvKtMXeA/CzCq5QJhZJRcIM6uUXYHo712Gc85NmZ0q\n99ozT+GcI9/G7OkH15bZLodtkVWBaGtrY/pxR3PZL6/itjvu4sLZs1h8Vz0HmVJlOzd9dsox7zLl\nEKZ+7axashrlsi2yKhDuMpxvbsrslGMePX4SGw4bUUtWo1y2RVYFwl2G881Nmd0T3bLrlsu2SNmT\ncmdJCxpuT0uanmp9Zla/ZBOlIuJuYAKApIHAcuDSVjLdZTjf3JTZKcecSi7boqfeYrwLuD8iHmol\nxF2G881NmZ1yzKnksi16aqr1YcCsVkPcZTjf3JTZKcc89/QTeWTRPJ5f9STnTtuXyYcezbj93t9y\nbi7bIvnFe8t2c48A4yPisQ6eb2x7P/Ge+1vayTBbJz4Xo9CbF+99LzC/o+IAEBEzI2JSREwaNXJU\nDwzHzJrVEwXicGp4e2FmPS/1xXs3Bt4NXJJyPWaWRuqu1quB16dch5mlk9VMSjPrWS4QZlbJBcLM\nKrlAmFklFwgzq+Su1tavpZrxmGqGJvTsLE3vQZhZJRcIM6vkAmFmlVwgzKxSdgXCLdnzzU2ZnVtu\nLu30syoQbsmeb27K7NxyIZ92+lkVCLdkzzc3ZXZuuZBPO/2sCoRbsuebmzI7t9yUsml7DyDp85IW\nSVooaZakjVKuz8zqlfK6GGOA44BJEbErMJCieW23uSV7vrkps3PLTSm3tveDgCGSBgFDKZrXdptb\nsuebmzI7t9yUsml7HxHLJc0A/gw8B8yNiLlrL7dWV+tOM92SPd/clNm55UI+7fSTtb2XtBlwMXAo\n8CRwIXBRRJxX9ZqJEyfF9TfdkmQ8Zj0pt5O1eqPt/X7A0ohYGREvUTSu3Tvh+sysZikLxJ+BvSQN\nlSSKy+8tTrg+M6tZsgIRETcBFwHzgTvLdc1MtT4zq1/qtvenAqemXIeZpZPVTEoz61kuEGZWyQXC\nzCq5QJhZJRcIM6vktvdmCaRsTZ9ilubDTz3f4ePegzCzSi4QZlbJBcLMKmVXINxxOd/clNm55abK\nrrtbdlYFwh2X881NmZ1bbsrsurtlZ1Ug3HE539yU2bnlpsyuu1t2VgXCHZfzzU2ZnVtu6uw6pe5q\nfXzZ0XqRpOkp12Vm9UvZ1XpXYBqwB7AbMFXSjq1kuuNyvrkps3PLTZ1dp5R7EG8CboqIZyNiDfB7\n4B9aCXTH5XxzU2bnlps6u04pp1ovBE6T9HqKrtYHAK/pSOuu1v0jN2V2brkps+vulp2sqzWApKOA\nzwGrgUXACxFReSzCXa3NupbiXIwLv/QhHr9vYY92tSYizo6IiRHxduBvwD0p12dm9Up6NqekzSPi\ncUnbUBx/2Cvl+sysXqlP9764PAbxEnB0RDyZeH1mVqPUXa3fljLfzNLKaialmfUsFwgzq+QCYWaV\nXCDMrJILhJlVSjqTcl1JWgk81OTiI4EnEgwjt9yU2bnlpsxe33PfEBGj1n6wTxWIdSHploiY1N9z\nU2bnlpsyu7/m+i2GmVVygTCzSjkXiJnOTZ6dW27K7H6Zm+0xCDNLL+c9CDNLzAXCzCq5QJhZpdT9\nIGohaRfgYKC97e9y4PKIWNx7o+odkvYAIiLmSRoH7A8siYhf1byen0bER+vM7O8kDQYOAx6JiF9L\n+jCwN7AYmBkRL/XqADvQ5w9SSvoycDgwG1hWPjyWYkPPjoh6L5hYk7KojaHo7P1Mw+P7R8TV3cw8\nFXgvRWG/BtgT+C3wbmBORJzWzdzL134IeCdwLUBE1NZuWdJbKS6FsDAi5raQsyewOCKeljQEOAnY\nHbgL+JeIeKqF7OOASyPi4S4XXrfcn1P87IYCTwLDgEuAd1H8LX6sheztKbq2bQ20UbR3PD8inm5p\n0BHRp2/lN7pBB48PBu5NuN4jW3jtccDdwH8DDwIHNzw3v4XcO4GBFL9gTwOblI8PAe5oIXc+cB4w\nBXhH+e+j5dfvaHE73tzw9TRgAXAqcD1wUgu5i4BB5dczge8Dby2zL2lxzE8BjwB/pGi6PKqm36k7\nyn8HAY8BA8v7avHndxwwFzgF+BNwJnAaRbGc0tKY6/jGU96AJRTzxNd+/A3A3QnX++cWXnsnMKz8\neluKdv/Hl/dvayH3to6+Lu8vaCF3APB5ir2SCeVjD9S0HRvHPK/9jw3YGLizhdzFDV/PX+u5bm+L\n9jGX2+Q9wNnASuBq4GPA8BZyF1L8x7YZsAp4Xfn4Ro3fTzd/39qLzVDgd+XX27Ty+xYRWRyDmA78\nRtK9QPsu3zbAjsAxrQRLuqPqKWCLFqIHRPm2IiIelDQFuEjSG8rs7npR0tCIeBaY+MpgpRHAy90N\njYiXge9JurD89zHqOz41QNJmFH9wioiV5TpXS1rTQu5CSUdGxDnA7ZImRcQtknai6IHaiii3yVxg\nrqQNKN7aHQ7MAF5zUlOTzqb4D28gcDJwoaQHKJo5z25xzIMo3lpsSPHWhYj4czn27qvjf4nUN4pf\nrr2A95e3vSgrZou5jwETKPZGGm/bUhxI6m7utZT/Ezc8Ngj4KdDWQu6GFY+PBN5c4/Y+kOJ9fB1Z\nDwIPAEvLf7cqHx9Ga3s9I4CfAPcDN1EUhQcoruC2W4tjrvxfFxjaYvZoYHT59abAB4A9Wsw8HrgD\n+DFFATqyfHwU8IdWsvv8QcqUJJ0NnBMR13Xw3PkR8eFu5o4F1kTEig6e2yciru9O7vpE0lBgi4hY\n2mLOJsB2FAV4WUQ8VsPYdoqIrK7hImk8xeUuF0bEktpy+3OBMLPOeaKUmVVygTCzSi4QmZLUJmmB\npIWSLizf03c3a4qkK8qvD5J0UifLbirpc91Yx9clndjs42st8xNJH1iHdW0raeG6jtFeywUiX89F\nxISI2BV4EfhM45MqrPPPNyIuj85np25KMXnI+gEXiPXDH4Edy/8575b0U4pJOVtLeo+kGyTNL/c0\nhkEx5VvSEknzKaboUj7+cUlnlF9vIelSSbeXt72BbwE7lHsv3ymX+6KkeZLukPSNhqyTJd0j6Tpg\n566+CUnTypzbJV281l7RfpJuKfOmlssPlPSdhnV/utUNaa/mApE5SYMoJvHcWT70RuDfI2I8sJpi\n+u1+EbE7xYzOEyRtRPGZ+fsoJlxtWRH/Q+D3EbEbxXkOiyjOebi/3Hv5oqT3lOvcg2JOyURJb5c0\nkeJ8mQnAAcDkJr6dSyJicrm+xcBRDc9tW67jQOBH5fdwFPBUREwu86dJ2q6J9ViTcphJaR0bImlB\n+fUfKWbpjQYeiogby8f3AsYB10uCYprvDcAuwNKIuBdA0nnApzpYx77ARwEiog14qpwV2eg95e22\n8v4wioIxnOKEp2fLdax9QlhHdpX0zxRvY4YBcxqe+0UUsxvvLWcf7lKu9+8ajk+MKNed1RyGvswF\nIl/PRcSExgfKIrC68SHgmog4fK3lXvW6Fgn4/xFx1lrrmN6NrJ8Ah0TE7ZI+TnHSWLu1J+xEue5j\nI6KxkCBp226s2zrgtxjrtxuBfSTtCCBp4/JchSXAtpJ2KJc7vOL1vwE+W752YHnOxyqKvYN2c4BP\nNBzbGCNpc+APwCGShkgaTvF2pivDgUfL8weOWOu5D0oaUI55e4qzZecAn20/30DSTpI2bmI91iTv\nQazHImJl+T/xLEkblg+fEhH3SPoUcKWkZyneogzvIOJ4YKakoyhOBPpsRNwg6fryY8SryuMQbwJu\nKPdgngH+MSLmS7oAuB14nOJMzq58jeK8ipXlv41j+jNwM7AJ8JmIeF7Sf1Icm5ivYuUrgUOa2zrW\nDE+1NrNKfothZpVcIMyskguEmVVygTCzSi4QZlbJBcLMKrlAmFml/wGGKSsV6cNDHgAAAABJRU5E\nrkJggg==\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "YYdbep8GNCaF"
      },
      "source": [
        "### 5b (optional) Training on a GPU\n",
        "\n",
        "One of the main advantages that Tensors have over NumPy arrays, and which make them so powerful, is that they can be easily moved to a GPU.\n",
        "\n",
        "Why GPU?\n",
        "\n",
        "- many cores = faster at parallel tasks\n",
        "- CPU vs GPU benchmarks training a CNN https://github.com/jcjohnson/cnn-benchmarks\n",
        "\n",
        "Where's the data?\n",
        "Where's the model?\n",
        "Where does the data go when you train the model?\n",
        "\n",
        "![computer.png](https://drive.google.com/uc?id=11uBHkC5tznLhNIGAn0mrggSC2LMEXlYC)\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "acW0dypgNCaG"
      },
      "source": [
        "First get PyTorch to find the device available."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "TTJsIcvbNCaH",
        "outputId": "dc4c2d64-75bb-4c63-fcb4-2f9142c29490",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "# Device configuration - defaults to CPU unless GPU is available on device\n",
        "device = torch.device('cuda:0' if torch.cuda.is_available() else 'cpu')\n",
        "device"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "device(type='cuda', index=0)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 37
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "iKsjBcL-NCaJ"
      },
      "source": [
        "How do we put the **model** on the GPU?"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "HMQzKKe4NCaK",
        "colab": {}
      },
      "source": [
        "model_gpu = LinearClassifier().to(device)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "4zJYcHCfNCaQ"
      },
      "source": [
        "How do we put the **data** on the GPU? (Below code is a copy of the training code above, just simplified without comments and loss printing.)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "6fq3hndyNCaR",
        "colab": {}
      },
      "source": [
        "def train_model_epochs2(num_epochs):\n",
        "    \"\"\" Copy of function train_model_epochs but explicitly copying data to device \n",
        "        during training. \n",
        "    \"\"\"\n",
        "    for epoch in range(num_epochs):\n",
        "\n",
        "        running_loss = 0.0\n",
        "        for i, data in enumerate(train_loader, 0):\n",
        "            images, labels = data\n",
        "\n",
        "            # Explicitly specifies that data is to be copied onto the device!\n",
        "            images = images.to(device)  # <----------- And note it's NOT an in-place operation; original\n",
        "            labels = labels.to(device)  # <----------- variables still exist on CPU\n",
        "\n",
        "            optimizer.zero_grad()\n",
        "            outputs = model_gpu(images)\n",
        "\n",
        "            loss = criterion(outputs, labels)\n",
        "            loss.backward()\n",
        "\n",
        "            optimizer.step()\n",
        "            running_loss += loss.item()\n",
        "            if i % 1000 == 999:    # print every 1000 mini-batches\n",
        "                print('Epoch / Batch [%d / %d] - Loss: %.3f' %\n",
        "                      (epoch + 1, i + 1, running_loss / 1000))\n",
        "                running_loss = 0.0"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "BJ4fN7UKcsQS"
      },
      "source": [
        "Train an identical second model on the GPU."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "2UyKM5Z9NCaU",
        "colab": {}
      },
      "source": [
        "# gpu_train_time = timeit.timeit(\n",
        "#     \"train_model_epochs2(num_epochs)\",\n",
        "#     setup=\"num_epochs=6\",\n",
        "#     number=1,\n",
        "#     globals=globals(),\n",
        "# )"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "c19bEzAIX3Vq"
      },
      "source": [
        "Feel free to compare **cpu_train_time** with **gpu_train_time**, keeping in mind that an inappropriate batch size may give you surprising results! Remember that copying data to the GPU also has an overhead.\n",
        "\n",
        "For those curious about optimisation on a GPU, NVidia's article on [NVidia's Deep Learning Performance Guide](https://docs.nvidia.com/deeplearning/sdk/dl-performance-guide/index.html) is helpful."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "bbdD8W2YVpSV",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "_ve5aTtfXWKQ",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}